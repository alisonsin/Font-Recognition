{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training Sets\nX = pd.read_csv('/kaggle/input/font-recognition/train_data.csv')\ny = pd.read_csv('/kaggle/input/font-recognition/train_labels.csv')\n#Testing Sets\nActualX = pd.read_csv('/kaggle/input/font-recognition/test_data.csv')\n\n#Convert train_labels from string -> numbers\nvals_to_replace = {'ARIAL':0, 'TIMES':1, 'SERIF':2, 'CAMBRIA': 3, 'CALIBRI': 4,'TAHOMA': 5 }\ny['Font'] = y['Font'].map(vals_to_replace)\n\n#Split training data into Training, Testing subsets; Introduce randomness in them with shuffle and random_state\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True,random_state=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To preserve orginal y_test shape for accuracy_score during Test\naftery_test = y_test ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Segregate Data Types:\n1. image data\n2. categorical data (Boolean)\n3. numerical data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rc = X_train.iloc[:, 7:len(X_train)]/255\nX_train_cat = X_train.iloc[:, 1:3]\nX_train_num = X_train.iloc[:, np.r_[0,3:7]]\n\nX_test_rc = X_test.iloc[:, 7:len(X_test)]/255\nX_test_cat = X_test.iloc[:, 1:3]\nX_test_num = X_test.iloc[:, np.r_[0,3:7]]\n\nActualX_rc = ActualX.iloc[:, 7:len(ActualX)]/255\nActualX_cat = ActualX.iloc[:, 1:3]\nActualX_num = ActualX.iloc[:, np.r_[0,3:7]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. Preprocess Image Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import skimage\nimport skimage.feature\n\n#creating empty arrays\ned_X_train_rc = np.zeros((len(X_train_rc),20,20))\ned_X_test_rc = np.zeros((len(X_test_rc),20,20))\ned_ActualX_rc = np.zeros((len(ActualX_rc),20,20))\n\ndef imgprep(df, newarr):\n    for i in range(len(df)):\n        img= np.array(df.iloc[i]).reshape(20,20)\n        ed = skimage.feature.canny(image= img,sigma = 0.15)\n        newarr[i] = ed    \n\n#training set, testing set, actual test set\nimgprep(X_train_rc, ed_X_train_rc)\nimgprep(X_test_rc, ed_X_test_rc)\nimgprep(ActualX_rc, ed_ActualX_rc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rescale for Inputing into NN\nimg_X_train = ed_X_train_rc.reshape(45500,20,20,1)  #shape rescaling\nimg_X_test = ed_X_test_rc.reshape(19500,20,20,1)\nimg_ActualX = ed_ActualX_rc.reshape(29221,20,20,1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Preprocessing 2) Catagorical + 3) Numerical Data\n    * for X_train_cat[\"strength\"] -> [0.4, 0.7]; w count [25568, 19932]\n    * for X_train_cat[\"italic\"] -> [0,1]; w count [26305, 19195]\n    \n    \n    \n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change 2) Categorical Data into [0,1] - i.e. only 'strength' column\nstr_bool_replace = {0.4:0, 0.7:1}\nX_train_cat[\"strength\"] = X_train_cat[\"strength\"].map(str_bool_replace)\nX_test_cat[\"strength\"] = X_test_cat[\"strength\"].map(str_bool_replace)\nActualX_cat[\"strength\"] = ActualX_cat[\"strength\"].map(str_bool_replace)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change 3) Numerical Data into the range [0,1]\nfrom sklearn.preprocessing import MinMaxScaler\ntraincs = MinMaxScaler(feature_range =(0, 1))\nX_train_num = traincs.fit_transform(X_train_num)\nX_test_num = traincs.transform(X_test_num)  \nActualX_num = traincs.transform(ActualX_num)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Concatenating 2) Categorical and 3) Numerical Tgt\nX_train_core = np.hstack([X_train_num, X_train_cat])\nX_test_core = np.hstack([X_test_num, X_test_cat])\nActualX_core = np.hstack([ActualX_num, ActualX_cat])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Neural Network Model"},{"metadata":{},"cell_type":"markdown","source":"## Multi-Layer Perceptron Layer for Categorical + Numerical Data"},{"metadata":{},"cell_type":"markdown","source":"### Prep output layer for NN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from  keras.utils import np_utils\nnny_train = np_utils.to_categorical(y_train)\nnny_test = np_utils.to_categorical(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Activation, Flatten, MaxPool2D, ZeroPadding2D, AveragePooling2D\nfrom keras.layers import Conv2D, BatchNormalization, Input, concatenate, Add   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mlp(core_inputs):\n    x = Dense(64,activation=\"relu\")(core_inputs)  #after passing input in layer -> x = output\n    core_outputs = Dense(6,activation=\"softmax\")(x)\n    return core_outputs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CNN for Image Pixel Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def cnn(img_inputs):\n    x = Conv2D(36,kernel_size=5,activation='relu')(img_inputs)\n    x = BatchNormalization()(x)\n    x = Dropout(0.1)(x)\n    \n    x = Conv2D(64,kernel_size=5,strides=1,padding='same',activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.1)(x)    \n    \n    x = Flatten()(x)\n    x = Dense(72, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.1)(x)\n    \n    img_outputs = Dense(6, activation='softmax', kernel_regularizer='l2')(x)\n\n    \n    return img_outputs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Combine them tgt!"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Lambda\nfrom keras.optimizers import Adam\n\ncore_inputs = Input(shape = (7))\nmlp_NN = mlp(core_inputs)\nimg_inputs = Input(shape=(20,20,1))\n\ncnn_NN = cnn(img_inputs)\ncombineInput = concatenate([mlp_NN, cnn_NN])\n\nfinal = Dense(units = 256, activation = \"relu\")(combineInput)\noutput_final = Dense(units = 6, activation = \"softmax\")(final)\n\nmodel = Model(inputs = [core_inputs, img_inputs], outputs = [output_final])   \nmodel.compile(optimizer=Adam(lr=0.01), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Traing the model!"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import LearningRateScheduler\nannealer = LearningRateScheduler(lambda x: 0.01 * 0.95 ** x) #decrease lr by 0.95 per epoch\n\nmodel.fit([X_train_core, img_X_train], nny_train,\n          batch_size=32,\n          epochs=50,\n          validation_data=([X_test_core, img_X_test],  nny_test), callbacks=[annealer])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict Test Data - Test for Accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"results = np.zeros((X_test.shape[0],6)) \nresults = results + model.predict([X_test_core, img_X_test])\nresults = np.argmax(results,axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(aftery_test,results)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Actual Submision Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"actualresults = np.zeros((29221,6)) \nactualresults = 29221 + model.predict([ActualX_core, img_ActualX])\nactualresults = np.argmax(actualresults,axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert labels from 'int' back to 'str'\nstractualresults = []\nfor i in range(len(actualresults)):\n    if actualresults[i] == 0:\n        stractualresults.append('ARIAL')\n    elif actualresults[i] == 1:\n        stractualresults.append('TIMES')\n    elif actualresults[i] == 2:\n        stractualresults.append('SERIF')\n    elif actualresults[i] == 3:\n        stractualresults.append('CAMBRIA')\n    elif actualresults[i] == 4: \n        stractualresults.append('CALIBRI')\n    elif actualresults[i] == 5:\n        stractualresults.append('TAHOMA')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdresults = pd.Series(stractualresults,name=\"Font\")\nsubmission = pd.concat([pd.Series(range(1,29222),name = \"ID\"),pdresults],axis = 1)\nsubmission.to_csv(\"mix_6.csv\",index=False)\nsubmission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Attempted Used of Transfer Learning (resnet50) that ended up never being incorporated into the CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\ncolored_img_x_train = []\nfor i in range(len(img_X_train)):\n    a = img_X_train[i]\n    colored_img_x_train.append( cv2.merge((a,a,a)) )\n\n\ncolored_img_x_test = []\nfor i in range(len(img_X_test)):\n    a = img_X_test[i]\n    colored_img_x_test.append( cv2.merge((a,a,a)) )\n\n\nprint(np.shape(colored_img_x_test))\n\n\nimport tensorflow.keras as K\ninput_img = K.Input(shape=(20,20,3))\nres_model = K.applications.ResNet50(include_top=False,\n                                        weights=\"imagenet\",\n                                        input_tensor=input_img)\n\nfor layer in res_model.layers[:39]:\n    layer.trainable = False\n\nfor i, layer in enumerate(res_model.layers):\n    print(i, layer.name, \"-\", layer.trainable)\n    \nto_res = (20, 20)\nmodel = K.models.Sequential()\nmodel.add(K.layers.Lambda(lambda image: tf.image.resize(image, to_res))) \nmodel.add(res_model)\nmodel.add(K.layers.Flatten())\nmodel.add(K.layers.BatchNormalization())\nmodel.add(K.layers.Dense(256, activation='relu'))\nmodel.add(K.layers.Dropout(0.5))\nmodel.add(K.layers.BatchNormalization())\nmodel.add(K.layers.Dense(6, activation='softmax'))\n\nimport tensorflow as tf \nfrom keras.optimizers import Adam\nmodel.compile(loss='categorical_crossentropy',\n                  optimizer=Adam(lr=0.01),\n                  metrics=['accuracy'])\n\nmodel.fit(np.array(colored_img_x_train), nny_train,\n          batch_size=32,\n          epochs=30,\n          validation_data=(np.array(colored_img_x_test),  nny_test))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}